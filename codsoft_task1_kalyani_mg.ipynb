{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNl5Bil0/lCfluV8arEg1QG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalyani-m-g/CODSOFT/blob/main/codsoft_task1_kalyani_mg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX9il90S8APG"
      },
      "outputs": [],
      "source": [
        "!pip install -q kagglehub transformers datasets accelerate torch scikit-learn\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\n",
        "    \"hijest/genre-classification-dataset-imdb\"\n",
        ")\n",
        "\n",
        "data_dir = os.path.join(path, \"Genre Classification Dataset\")\n",
        "train_file = os.path.join(data_dir, \"train_data.txt\")\n"
      ],
      "metadata": {
        "id": "ucrNLOm-8Erq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\n",
        "    train_file,\n",
        "    sep=\" ::: \",\n",
        "    engine=\"python\",\n",
        "    names=[\"id\", \"title\", \"genre\", \"plot\"]\n",
        ")\n",
        "\n",
        "print(df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "rcXd2qcpARzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_counts = df[\"genre\"].value_counts()\n",
        "valid_genres = genre_counts[genre_counts >= 100].index\n",
        "\n",
        "df = df[df[\"genre\"].isin(valid_genres)].reset_index(drop=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"genre\"])\n",
        "\n",
        "num_labels = df[\"label\"].nunique()\n",
        "print(\"Number of labels:\", num_labels)"
      ],
      "metadata": {
        "id": "LCb94jJqAUGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df.sample(n=10000, random_state=42)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df_small,\n",
        "    test_size=0.2,\n",
        "    stratify=df_small[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df[[\"plot\", \"label\"]])\n",
        "val_dataset = Dataset.from_pandas(val_df[[\"plot\", \"label\"]])\n"
      ],
      "metadata": {
        "id": "fFZ49_FLAWQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"plot\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "\n",
        "train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
        ")\n",
        "\n",
        "val_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "VmXv9Ep6AYKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=200,\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "oxA2CwPFAhdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "j5GQ0E__Ajt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(val_dataset)\n",
        "\n",
        "y_true = preds.label_ids\n",
        "y_pred = np.argmax(preds.predictions, axis=1)\n",
        "\n",
        "print(\n",
        "    classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        target_names=label_encoder.classes_,\n",
        "        zero_division=0\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "xVGtL8IzAmKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"bert_genre_model\")\n",
        "tokenizer.save_pretrained(\"bert_genre_model\")\n"
      ],
      "metadata": {
        "id": "NY1sjv_DAn98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_genre(plot_text):\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        plot_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    pred_id = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return label_encoder.inverse_transform([pred_id])[0]"
      ],
      "metadata": {
        "id": "cyqvwiUiAp1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot = input(\"Enter movie plot:\\n\")\n",
        "print(\"Predicted Genre:\", predict_genre(plot))\n"
      ],
      "metadata": {
        "id": "IBkFAvQpArrW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}